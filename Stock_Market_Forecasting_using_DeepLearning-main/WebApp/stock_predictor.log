2025-03-16 14:53:45,600 ERROR [stock_predictor.py:74] - No data fetched for INVALID
2025-03-16 14:53:45,601 INFO [stock_predictor.py:86] - Preparing data for GOOGL
2025-03-16 14:53:45,601 INFO [stock_predictor.py:87] - Input data shape: (79, 6)
2025-03-16 14:53:45,604 INFO [stock_predictor.py:97] - Calculating technical indicators...
2025-03-16 14:53:45,607 INFO [stock_predictor.py:102] - Normalizing features...
2025-03-16 14:53:45,613 INFO [stock_predictor.py:108] - Final data shape: (79, 12)
2025-03-16 14:53:45,614 INFO [stock_predictor.py:117] - Loading model for GOOGL
2025-03-16 14:53:45,775 ERROR [stock_predictor.py:200] - Error loading model weights: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.Close_center.weight", "prescalers.Close_center.bias", "prescalers.Close_scale.weight", "prescalers.Close_scale.bias", "prescalers.time_idx.weight", "prescalers.time_idx.bias", "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.Open.weight", "prescalers.Open.bias", "prescalers.High.weight", "prescalers.High.bias", "prescalers.Low.weight", "prescalers.Low.bias", "prescalers.Close.weight", "prescalers.Close.bias", "prescalers.Volume.weight", "prescalers.Volume.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "static_variable_selection.single_variable_grns.Close_center.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_center.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_center.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_center.fc1.weight", "static_variable_selection.single_variable_grns.Close_center.fc1.bias", "static_variable_selection.single_variable_grns.Close_center.fc2.weight", "static_variable_selection.single_variable_grns.Close_center.fc2.bias", "static_variable_selection.single_variable_grns.Close_center.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_center.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_center.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_center.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_scale.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_scale.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_scale.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_scale.fc1.weight", "static_variable_selection.single_variable_grns.Close_scale.fc1.bias", "static_variable_selection.single_variable_grns.Close_scale.fc2.weight", "static_variable_selection.single_variable_grns.Close_scale.fc2.bias", "static_variable_selection.single_variable_grns.Close_scale.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_scale.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_scale.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_scale.gate_norm.add_norm.norm.bias", "static_variable_selection.prescalers.Close_center.weight", "static_variable_selection.prescalers.Close_center.bias", "static_variable_selection.prescalers.Close_scale.weight", "static_variable_selection.prescalers.Close_scale.bias", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.fc1.weight", "encoder_variable_selection.single_variable_grns.Open.fc1.bias", "encoder_variable_selection.single_variable_grns.Open.fc2.weight", "encoder_variable_selection.single_variable_grns.Open.fc2.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.High.resample_norm.mask", "encoder_variable_selection.single_variable_grns.High.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.High.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.High.fc1.weight", "encoder_variable_selection.single_variable_grns.High.fc1.bias", "encoder_variable_selection.single_variable_grns.High.fc2.weight", "encoder_variable_selection.single_variable_grns.High.fc2.bias", "encoder_variable_selection.single_variable_grns.High.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.High.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.High.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.High.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Low.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Low.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Low.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Low.fc1.weight", "encoder_variable_selection.single_variable_grns.Low.fc1.bias", "encoder_variable_selection.single_variable_grns.Low.fc2.weight", "encoder_variable_selection.single_variable_grns.Low.fc2.bias", "encoder_variable_selection.single_variable_grns.Low.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Low.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Low.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Low.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Close.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Close.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Close.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Close.fc1.weight", "encoder_variable_selection.single_variable_grns.Close.fc1.bias", "encoder_variable_selection.single_variable_grns.Close.fc2.weight", "encoder_variable_selection.single_variable_grns.Close.fc2.bias", "encoder_variable_selection.single_variable_grns.Close.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Close.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Close.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Close.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.fc1.weight", "encoder_variable_selection.single_variable_grns.Volume.fc1.bias", "encoder_variable_selection.single_variable_grns.Volume.fc2.weight", "encoder_variable_selection.single_variable_grns.Volume.fc2.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time_idx.weight", "encoder_variable_selection.prescalers.time_idx.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.Open.weight", "encoder_variable_selection.prescalers.Open.bias", "encoder_variable_selection.prescalers.High.weight", "encoder_variable_selection.prescalers.High.bias", "encoder_variable_selection.prescalers.Low.weight", "encoder_variable_selection.prescalers.Low.bias", "encoder_variable_selection.prescalers.Close.weight", "encoder_variable_selection.prescalers.Close.bias", "encoder_variable_selection.prescalers.Volume.weight", "encoder_variable_selection.prescalers.Volume.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time_idx.weight", "decoder_variable_selection.prescalers.time_idx.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias". 
	Unexpected key(s) in state_dict: "prescalers.Close_GOOGL_center.weight", "prescalers.Close_GOOGL_center.bias", "prescalers.Close_GOOGL_scale.weight", "prescalers.Close_GOOGL_scale.bias", "prescalers.time.weight", "prescalers.time.bias", "prescalers.High_GOOGL.weight", "prescalers.High_GOOGL.bias", "prescalers.Low_GOOGL.weight", "prescalers.Low_GOOGL.bias", "prescalers.Close_GOOGL.weight", "prescalers.Close_GOOGL.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.bias", "static_variable_selection.prescalers.Close_GOOGL_center.weight", "static_variable_selection.prescalers.Close_GOOGL_center.bias", "static_variable_selection.prescalers.Close_GOOGL_scale.weight", "static_variable_selection.prescalers.Close_GOOGL_scale.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.mask", "encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.weight", "encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.bias", "encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.weight", "encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.bias", "encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.weight", "encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.bias", "encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.weight", "encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.bias", "encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.weight", "encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.bias", "encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.weight", "encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.bias", "encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "encoder_variable_selection.prescalers.High_GOOGL.weight", "encoder_variable_selection.prescalers.High_GOOGL.bias", "encoder_variable_selection.prescalers.Low_GOOGL.weight", "encoder_variable_selection.prescalers.Low_GOOGL.bias", "encoder_variable_selection.prescalers.Close_GOOGL.weight", "encoder_variable_selection.prescalers.Close_GOOGL.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias". 
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([11, 704]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([11, 128]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([11, 11]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([22, 11]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([22]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([11]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([4, 256]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([4, 128]).
	size mismatch for decoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([2, 2]) from checkpoint, the shape in current model is torch.Size([4, 4]).
	size mismatch for decoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([4, 2]) from checkpoint, the shape in current model is torch.Size([8, 4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
2025-03-16 15:09:05,056 ERROR [stock_predictor.py:74] - No data fetched for INVALID
2025-03-16 15:09:05,057 INFO [stock_predictor.py:86] - Preparing data for GOOGL
2025-03-16 15:09:05,065 INFO [stock_predictor.py:107] - Final data shape: (79, 16)
2025-03-16 15:09:05,066 INFO [stock_predictor.py:117] - Loading model for GOOGL
2025-03-16 15:09:05,352 ERROR [stock_predictor.py:195] - Error loading model weights: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.time_idx.weight", "prescalers.time_idx.bias", "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time_idx.weight", "encoder_variable_selection.prescalers.time_idx.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time_idx.weight", "decoder_variable_selection.prescalers.time_idx.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias". 
	Unexpected key(s) in state_dict: "prescalers.time.weight", "prescalers.time.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias". 
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([9, 576]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([9, 128]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([18, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([4, 256]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([4, 128]).
	size mismatch for decoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([2, 2]) from checkpoint, the shape in current model is torch.Size([4, 4]).
	size mismatch for decoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([4, 2]) from checkpoint, the shape in current model is torch.Size([8, 4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
2025-03-16 15:09:05,353 ERROR [stock_predictor.py:196] - Full traceback:
Traceback (most recent call last):
  File "C:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\stock_predictor.py", line 187, in load_model
    model.load_state_dict(state_dict)
  File "C:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\.venv\Lib\site-packages\torch\nn\modules\module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.time_idx.weight", "prescalers.time_idx.bias", "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time_idx.weight", "encoder_variable_selection.prescalers.time_idx.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time_idx.weight", "decoder_variable_selection.prescalers.time_idx.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias". 
	Unexpected key(s) in state_dict: "prescalers.time.weight", "prescalers.time.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias". 
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([9, 576]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([9, 128]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([18, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([4, 256]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([4, 128]).
	size mismatch for decoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([2, 2]) from checkpoint, the shape in current model is torch.Size([4, 4]).
	size mismatch for decoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([4, 2]) from checkpoint, the shape in current model is torch.Size([8, 4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([8]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([2]) from checkpoint, the shape in current model is torch.Size([4]).
2025-03-16 15:23:07,286 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_googl.pth
2025-03-16 15:23:07,287 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_amzn.pth
2025-03-16 15:23:07,287 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_ibm.pth
2025-03-16 15:23:07,287 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_aapl.pth
2025-03-16 15:23:09,437 ERROR [stock_predictor.py:74] - No data fetched for INVALID
2025-03-16 15:23:09,438 INFO [stock_predictor.py:86] - Preparing data for GOOGL
2025-03-16 15:23:09,438 INFO [stock_predictor.py:87] - Input data shape: (79, 6)
2025-03-16 15:23:09,447 INFO [stock_predictor.py:113] - Final data shape: (79, 15)
2025-03-16 15:23:09,448 INFO [stock_predictor.py:123] - Loading model for GOOGL
2025-03-16 15:23:09,706 ERROR [stock_predictor.py:199] - Error loading model weights: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.Open.weight", "prescalers.Open.bias", "prescalers.Volume.weight", "prescalers.Volume.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.fc1.weight", "encoder_variable_selection.single_variable_grns.Open.fc1.bias", "encoder_variable_selection.single_variable_grns.Open.fc2.weight", "encoder_variable_selection.single_variable_grns.Open.fc2.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.fc1.weight", "encoder_variable_selection.single_variable_grns.Volume.fc1.bias", "encoder_variable_selection.single_variable_grns.Volume.fc2.weight", "encoder_variable_selection.single_variable_grns.Volume.fc2.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.Open.weight", "encoder_variable_selection.prescalers.Open.bias", "encoder_variable_selection.prescalers.Volume.weight", "encoder_variable_selection.prescalers.Volume.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias", "lstm_encoder.weight_ih_l1", "lstm_encoder.weight_hh_l1", "lstm_encoder.bias_ih_l1", "lstm_encoder.bias_hh_l1", "lstm_decoder.weight_ih_l1", "lstm_decoder.weight_hh_l1", "lstm_decoder.bias_ih_l1", "lstm_decoder.bias_hh_l1". 
	Unexpected key(s) in state_dict: "prescalers.year.weight", "prescalers.year.bias", "prescalers.Close_GOOGL_center.weight", "prescalers.Close_GOOGL_center.bias", "prescalers.Close_GOOGL_scale.weight", "prescalers.Close_GOOGL_scale.bias", "prescalers.time.weight", "prescalers.time.bias", "prescalers.relative_time_idx.weight", "prescalers.relative_time_idx.bias", "static_variable_selection.single_variable_grns.year.resample_norm.mask", "static_variable_selection.single_variable_grns.year.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.year.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.year.fc1.weight", "static_variable_selection.single_variable_grns.year.fc1.bias", "static_variable_selection.single_variable_grns.year.fc2.weight", "static_variable_selection.single_variable_grns.year.fc2.bias", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.bias", "static_variable_selection.prescalers.year.weight", "static_variable_selection.prescalers.year.bias", "static_variable_selection.prescalers.Close_GOOGL_center.weight", "static_variable_selection.prescalers.Close_GOOGL_center.bias", "static_variable_selection.prescalers.Close_GOOGL_scale.weight", "static_variable_selection.prescalers.Close_GOOGL_scale.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "encoder_variable_selection.prescalers.relative_time_idx.weight", "encoder_variable_selection.prescalers.relative_time_idx.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias", "decoder_variable_selection.prescalers.relative_time_idx.weight", "decoder_variable_selection.prescalers.relative_time_idx.bias", "multihead_attn.q_layers.4.weight", "multihead_attn.q_layers.4.bias", "multihead_attn.q_layers.5.weight", "multihead_attn.q_layers.5.bias", "multihead_attn.q_layers.6.weight", "multihead_attn.q_layers.6.bias", "multihead_attn.q_layers.7.weight", "multihead_attn.q_layers.7.bias", "multihead_attn.k_layers.4.weight", "multihead_attn.k_layers.4.bias", "multihead_attn.k_layers.5.weight", "multihead_attn.k_layers.5.bias", "multihead_attn.k_layers.6.weight", "multihead_attn.k_layers.6.bias", "multihead_attn.k_layers.7.weight", "multihead_attn.k_layers.7.bias". 
	size mismatch for prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 257]) from checkpoint, the shape in current model is torch.Size([2, 33]).
	size mismatch for static_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([2, 2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([4, 2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.single_variable_grns.group.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for static_variable_selection.prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([9, 288]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([9, 64]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([18, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for static_context_variable_selection.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for lstm_encoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_encoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for post_lstm_gate_encoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_encoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_gate_decoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_decoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_add_norm_encoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_encoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.context.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for multihead_attn.v_layer.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.w_h.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([64, 16]).
	size mismatch for post_attn_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_attn_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_attn_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_attn_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pre_output_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pre_output_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for output_layer.weight: copying a param with shape torch.Size([7, 128]) from checkpoint, the shape in current model is torch.Size([7, 64]).
2025-03-16 15:23:09,711 ERROR [stock_predictor.py:200] - Full traceback:
Traceback (most recent call last):
  File "c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\stock_predictor.py", line 191, in load_model
    model.load_state_dict(state_dict)
  File "C:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\.venv\Lib\site-packages\torch\nn\modules\module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.Open.weight", "prescalers.Open.bias", "prescalers.Volume.weight", "prescalers.Volume.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.fc1.weight", "encoder_variable_selection.single_variable_grns.Open.fc1.bias", "encoder_variable_selection.single_variable_grns.Open.fc2.weight", "encoder_variable_selection.single_variable_grns.Open.fc2.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.fc1.weight", "encoder_variable_selection.single_variable_grns.Volume.fc1.bias", "encoder_variable_selection.single_variable_grns.Volume.fc2.weight", "encoder_variable_selection.single_variable_grns.Volume.fc2.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.Open.weight", "encoder_variable_selection.prescalers.Open.bias", "encoder_variable_selection.prescalers.Volume.weight", "encoder_variable_selection.prescalers.Volume.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias", "lstm_encoder.weight_ih_l1", "lstm_encoder.weight_hh_l1", "lstm_encoder.bias_ih_l1", "lstm_encoder.bias_hh_l1", "lstm_decoder.weight_ih_l1", "lstm_decoder.weight_hh_l1", "lstm_decoder.bias_ih_l1", "lstm_decoder.bias_hh_l1". 
	Unexpected key(s) in state_dict: "prescalers.year.weight", "prescalers.year.bias", "prescalers.Close_GOOGL_center.weight", "prescalers.Close_GOOGL_center.bias", "prescalers.Close_GOOGL_scale.weight", "prescalers.Close_GOOGL_scale.bias", "prescalers.time.weight", "prescalers.time.bias", "prescalers.relative_time_idx.weight", "prescalers.relative_time_idx.bias", "static_variable_selection.single_variable_grns.year.resample_norm.mask", "static_variable_selection.single_variable_grns.year.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.year.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.year.fc1.weight", "static_variable_selection.single_variable_grns.year.fc1.bias", "static_variable_selection.single_variable_grns.year.fc2.weight", "static_variable_selection.single_variable_grns.year.fc2.bias", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.bias", "static_variable_selection.prescalers.year.weight", "static_variable_selection.prescalers.year.bias", "static_variable_selection.prescalers.Close_GOOGL_center.weight", "static_variable_selection.prescalers.Close_GOOGL_center.bias", "static_variable_selection.prescalers.Close_GOOGL_scale.weight", "static_variable_selection.prescalers.Close_GOOGL_scale.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "encoder_variable_selection.prescalers.relative_time_idx.weight", "encoder_variable_selection.prescalers.relative_time_idx.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias", "decoder_variable_selection.prescalers.relative_time_idx.weight", "decoder_variable_selection.prescalers.relative_time_idx.bias", "multihead_attn.q_layers.4.weight", "multihead_attn.q_layers.4.bias", "multihead_attn.q_layers.5.weight", "multihead_attn.q_layers.5.bias", "multihead_attn.q_layers.6.weight", "multihead_attn.q_layers.6.bias", "multihead_attn.q_layers.7.weight", "multihead_attn.q_layers.7.bias", "multihead_attn.k_layers.4.weight", "multihead_attn.k_layers.4.bias", "multihead_attn.k_layers.5.weight", "multihead_attn.k_layers.5.bias", "multihead_attn.k_layers.6.weight", "multihead_attn.k_layers.6.bias", "multihead_attn.k_layers.7.weight", "multihead_attn.k_layers.7.bias". 
	size mismatch for prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 257]) from checkpoint, the shape in current model is torch.Size([2, 33]).
	size mismatch for static_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([2, 2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([4, 2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.single_variable_grns.group.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for static_variable_selection.prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([9, 288]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([9, 64]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([18, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for static_context_variable_selection.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for lstm_encoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_encoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for post_lstm_gate_encoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_encoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_gate_decoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_decoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_add_norm_encoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_encoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.context.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for multihead_attn.v_layer.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.w_h.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([64, 16]).
	size mismatch for post_attn_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_attn_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_attn_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_attn_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pre_output_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pre_output_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for output_layer.weight: copying a param with shape torch.Size([7, 128]) from checkpoint, the shape in current model is torch.Size([7, 64]).
2025-03-20 14:40:23,727 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_googl.pth
2025-03-20 14:40:23,728 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_amzn.pth
2025-03-20 14:40:23,728 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_ibm.pth
2025-03-20 14:40:23,728 INFO [stock_predictor.py:271] - Model file found: c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\Models\model_aapl.pth
2025-03-20 14:40:26,255 ERROR [stock_predictor.py:74] - No data fetched for INVALID
2025-03-20 14:40:26,255 INFO [stock_predictor.py:86] - Preparing data for GOOGL
2025-03-20 14:40:26,256 INFO [stock_predictor.py:87] - Input data shape: (80, 6)
2025-03-20 14:40:26,282 INFO [stock_predictor.py:113] - Final data shape: (80, 15)
2025-03-20 14:40:26,285 INFO [stock_predictor.py:123] - Loading model for GOOGL
2025-03-20 14:40:26,721 ERROR [stock_predictor.py:199] - Error loading model weights: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.Open.weight", "prescalers.Open.bias", "prescalers.Volume.weight", "prescalers.Volume.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.fc1.weight", "encoder_variable_selection.single_variable_grns.Open.fc1.bias", "encoder_variable_selection.single_variable_grns.Open.fc2.weight", "encoder_variable_selection.single_variable_grns.Open.fc2.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.fc1.weight", "encoder_variable_selection.single_variable_grns.Volume.fc1.bias", "encoder_variable_selection.single_variable_grns.Volume.fc2.weight", "encoder_variable_selection.single_variable_grns.Volume.fc2.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.Open.weight", "encoder_variable_selection.prescalers.Open.bias", "encoder_variable_selection.prescalers.Volume.weight", "encoder_variable_selection.prescalers.Volume.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias", "lstm_encoder.weight_ih_l1", "lstm_encoder.weight_hh_l1", "lstm_encoder.bias_ih_l1", "lstm_encoder.bias_hh_l1", "lstm_decoder.weight_ih_l1", "lstm_decoder.weight_hh_l1", "lstm_decoder.bias_ih_l1", "lstm_decoder.bias_hh_l1". 
	Unexpected key(s) in state_dict: "prescalers.year.weight", "prescalers.year.bias", "prescalers.Close_GOOGL_center.weight", "prescalers.Close_GOOGL_center.bias", "prescalers.Close_GOOGL_scale.weight", "prescalers.Close_GOOGL_scale.bias", "prescalers.time.weight", "prescalers.time.bias", "prescalers.relative_time_idx.weight", "prescalers.relative_time_idx.bias", "static_variable_selection.single_variable_grns.year.resample_norm.mask", "static_variable_selection.single_variable_grns.year.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.year.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.year.fc1.weight", "static_variable_selection.single_variable_grns.year.fc1.bias", "static_variable_selection.single_variable_grns.year.fc2.weight", "static_variable_selection.single_variable_grns.year.fc2.bias", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.bias", "static_variable_selection.prescalers.year.weight", "static_variable_selection.prescalers.year.bias", "static_variable_selection.prescalers.Close_GOOGL_center.weight", "static_variable_selection.prescalers.Close_GOOGL_center.bias", "static_variable_selection.prescalers.Close_GOOGL_scale.weight", "static_variable_selection.prescalers.Close_GOOGL_scale.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "encoder_variable_selection.prescalers.relative_time_idx.weight", "encoder_variable_selection.prescalers.relative_time_idx.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias", "decoder_variable_selection.prescalers.relative_time_idx.weight", "decoder_variable_selection.prescalers.relative_time_idx.bias", "multihead_attn.q_layers.4.weight", "multihead_attn.q_layers.4.bias", "multihead_attn.q_layers.5.weight", "multihead_attn.q_layers.5.bias", "multihead_attn.q_layers.6.weight", "multihead_attn.q_layers.6.bias", "multihead_attn.q_layers.7.weight", "multihead_attn.q_layers.7.bias", "multihead_attn.k_layers.4.weight", "multihead_attn.k_layers.4.bias", "multihead_attn.k_layers.5.weight", "multihead_attn.k_layers.5.bias", "multihead_attn.k_layers.6.weight", "multihead_attn.k_layers.6.bias", "multihead_attn.k_layers.7.weight", "multihead_attn.k_layers.7.bias". 
	size mismatch for prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 257]) from checkpoint, the shape in current model is torch.Size([2, 33]).
	size mismatch for static_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([2, 2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([4, 2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.single_variable_grns.group.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for static_variable_selection.prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([9, 288]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([9, 64]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([18, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for static_context_variable_selection.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for lstm_encoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_encoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for post_lstm_gate_encoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_encoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_gate_decoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_decoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_add_norm_encoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_encoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.context.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for multihead_attn.v_layer.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.w_h.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([64, 16]).
	size mismatch for post_attn_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_attn_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_attn_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_attn_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pre_output_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pre_output_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for output_layer.weight: copying a param with shape torch.Size([7, 128]) from checkpoint, the shape in current model is torch.Size([7, 64]).
2025-03-20 14:40:26,729 ERROR [stock_predictor.py:200] - Full traceback:
Traceback (most recent call last):
  File "c:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\WebApp\stock_predictor.py", line 191, in load_model
    model.load_state_dict(state_dict)
  File "C:\Users\deepa\OneDrive\Documents\Project Documents\Stock_Market_Forecasting_using_DeepLearning\.venv\Lib\site-packages\torch\nn\modules\module.py", line 2581, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for TemporalFusionTransformer:
	Missing key(s) in state_dict: "prescalers.month.weight", "prescalers.month.bias", "prescalers.day_of_week.weight", "prescalers.day_of_week.bias", "prescalers.Open.weight", "prescalers.Open.bias", "prescalers.Volume.weight", "prescalers.Volume.bias", "prescalers.MA7.weight", "prescalers.MA7.bias", "prescalers.MA21.weight", "prescalers.MA21.bias", "encoder_variable_selection.single_variable_grns.month.resample_norm.mask", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.month.fc1.weight", "encoder_variable_selection.single_variable_grns.month.fc1.bias", "encoder_variable_selection.single_variable_grns.month.fc2.weight", "encoder_variable_selection.single_variable_grns.month.fc2.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "encoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Open.fc1.weight", "encoder_variable_selection.single_variable_grns.Open.fc1.bias", "encoder_variable_selection.single_variable_grns.Open.fc2.weight", "encoder_variable_selection.single_variable_grns.Open.fc2.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Open.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.mask", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.Volume.fc1.weight", "encoder_variable_selection.single_variable_grns.Volume.fc1.bias", "encoder_variable_selection.single_variable_grns.Volume.fc2.weight", "encoder_variable_selection.single_variable_grns.Volume.fc2.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.Volume.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA7.fc1.weight", "encoder_variable_selection.single_variable_grns.MA7.fc1.bias", "encoder_variable_selection.single_variable_grns.MA7.fc2.weight", "encoder_variable_selection.single_variable_grns.MA7.fc2.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA7.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.mask", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.MA21.fc1.weight", "encoder_variable_selection.single_variable_grns.MA21.fc1.bias", "encoder_variable_selection.single_variable_grns.MA21.fc2.weight", "encoder_variable_selection.single_variable_grns.MA21.fc2.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.MA21.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.month.weight", "encoder_variable_selection.prescalers.month.bias", "encoder_variable_selection.prescalers.day_of_week.weight", "encoder_variable_selection.prescalers.day_of_week.bias", "encoder_variable_selection.prescalers.Open.weight", "encoder_variable_selection.prescalers.Open.bias", "encoder_variable_selection.prescalers.Volume.weight", "encoder_variable_selection.prescalers.Volume.bias", "encoder_variable_selection.prescalers.MA7.weight", "encoder_variable_selection.prescalers.MA7.bias", "encoder_variable_selection.prescalers.MA21.weight", "encoder_variable_selection.prescalers.MA21.bias", "decoder_variable_selection.single_variable_grns.month.resample_norm.mask", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.month.fc1.weight", "decoder_variable_selection.single_variable_grns.month.fc1.bias", "decoder_variable_selection.single_variable_grns.month.fc2.weight", "decoder_variable_selection.single_variable_grns.month.fc2.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.month.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.mask", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc1.bias", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.weight", "decoder_variable_selection.single_variable_grns.day_of_week.fc2.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.day_of_week.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.month.weight", "decoder_variable_selection.prescalers.month.bias", "decoder_variable_selection.prescalers.day_of_week.weight", "decoder_variable_selection.prescalers.day_of_week.bias", "lstm_encoder.weight_ih_l1", "lstm_encoder.weight_hh_l1", "lstm_encoder.bias_ih_l1", "lstm_encoder.bias_hh_l1", "lstm_decoder.weight_ih_l1", "lstm_decoder.weight_hh_l1", "lstm_decoder.bias_ih_l1", "lstm_decoder.bias_hh_l1". 
	Unexpected key(s) in state_dict: "prescalers.year.weight", "prescalers.year.bias", "prescalers.Close_GOOGL_center.weight", "prescalers.Close_GOOGL_center.bias", "prescalers.Close_GOOGL_scale.weight", "prescalers.Close_GOOGL_scale.bias", "prescalers.time.weight", "prescalers.time.bias", "prescalers.relative_time_idx.weight", "prescalers.relative_time_idx.bias", "static_variable_selection.single_variable_grns.year.resample_norm.mask", "static_variable_selection.single_variable_grns.year.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.year.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.year.fc1.weight", "static_variable_selection.single_variable_grns.year.fc1.bias", "static_variable_selection.single_variable_grns.year.fc2.weight", "static_variable_selection.single_variable_grns.year.fc2.bias", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.year.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.year.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_center.gate_norm.add_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.mask", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.resample_norm.norm.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc1.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.fc2.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.glu.fc.bias", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.weight", "static_variable_selection.single_variable_grns.Close_GOOGL_scale.gate_norm.add_norm.norm.bias", "static_variable_selection.prescalers.year.weight", "static_variable_selection.prescalers.year.bias", "static_variable_selection.prescalers.Close_GOOGL_center.weight", "static_variable_selection.prescalers.Close_GOOGL_center.bias", "static_variable_selection.prescalers.Close_GOOGL_scale.weight", "static_variable_selection.prescalers.Close_GOOGL_scale.bias", "encoder_variable_selection.single_variable_grns.time.resample_norm.mask", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.time.fc1.weight", "encoder_variable_selection.single_variable_grns.time.fc1.bias", "encoder_variable_selection.single_variable_grns.time.fc2.weight", "encoder_variable_selection.single_variable_grns.time.fc2.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "encoder_variable_selection.prescalers.time.weight", "encoder_variable_selection.prescalers.time.bias", "encoder_variable_selection.prescalers.relative_time_idx.weight", "encoder_variable_selection.prescalers.relative_time_idx.bias", "decoder_variable_selection.single_variable_grns.time.resample_norm.mask", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.time.fc1.weight", "decoder_variable_selection.single_variable_grns.time.fc1.bias", "decoder_variable_selection.single_variable_grns.time.fc2.weight", "decoder_variable_selection.single_variable_grns.time.fc2.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.time.gate_norm.add_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.mask", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.resample_norm.norm.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight", "decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias", "decoder_variable_selection.prescalers.time.weight", "decoder_variable_selection.prescalers.time.bias", "decoder_variable_selection.prescalers.relative_time_idx.weight", "decoder_variable_selection.prescalers.relative_time_idx.bias", "multihead_attn.q_layers.4.weight", "multihead_attn.q_layers.4.bias", "multihead_attn.q_layers.5.weight", "multihead_attn.q_layers.5.bias", "multihead_attn.q_layers.6.weight", "multihead_attn.q_layers.6.bias", "multihead_attn.q_layers.7.weight", "multihead_attn.q_layers.7.bias", "multihead_attn.k_layers.4.weight", "multihead_attn.k_layers.4.bias", "multihead_attn.k_layers.5.weight", "multihead_attn.k_layers.5.bias", "multihead_attn.k_layers.6.weight", "multihead_attn.k_layers.6.bias", "multihead_attn.k_layers.7.weight", "multihead_attn.k_layers.7.bias". 
	size mismatch for prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 257]) from checkpoint, the shape in current model is torch.Size([2, 33]).
	size mismatch for static_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([2, 2]).
	size mismatch for static_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([4, 2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([4]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([2]).
	size mismatch for static_variable_selection.single_variable_grns.group.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.group.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_variable_selection.prescalers.encoder_length.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for static_variable_selection.prescalers.encoder_length.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.mask: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.resample_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([5, 320]) from checkpoint, the shape in current model is torch.Size([9, 288]).
	size mismatch for encoder_variable_selection.flattened_grn.fc1.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([5, 128]) from checkpoint, the shape in current model is torch.Size([9, 64]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight: copying a param with shape torch.Size([10, 5]) from checkpoint, the shape in current model is torch.Size([18, 9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.High_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Low_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.mask: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.resample_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc1.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.weight: copying a param with shape torch.Size([64, 64]) from checkpoint, the shape in current model is torch.Size([32, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.fc2.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([128, 32]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.single_variable_grns.Close_GOOGL.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.High_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Low_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.weight: copying a param with shape torch.Size([64, 1]) from checkpoint, the shape in current model is torch.Size([32, 1]).
	size mismatch for encoder_variable_selection.prescalers.Close_GOOGL.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).
	size mismatch for decoder_variable_selection.flattened_grn.fc1.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for decoder_variable_selection.flattened_grn.context.weight: copying a param with shape torch.Size([2, 128]) from checkpoint, the shape in current model is torch.Size([2, 64]).
	size mismatch for static_context_variable_selection.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_variable_selection.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_variable_selection.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_variable_selection.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_hidden_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_hidden_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_initial_cell_lstm.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_initial_cell_lstm.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_context_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_context_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_context_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for lstm_encoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_encoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_encoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.weight_ih_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.weight_hh_l0: copying a param with shape torch.Size([512, 128]) from checkpoint, the shape in current model is torch.Size([256, 64]).
	size mismatch for lstm_decoder.bias_ih_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for lstm_decoder.bias_hh_l0: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for post_lstm_gate_encoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_encoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_gate_decoder.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_lstm_gate_decoder.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_lstm_add_norm_encoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_encoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_lstm_add_norm_decoder.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.context.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for static_enrichment.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for static_enrichment.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for static_enrichment.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for multihead_attn.v_layer.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.q_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.0.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.1.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.2.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.k_layers.3.weight: copying a param with shape torch.Size([16, 128]) from checkpoint, the shape in current model is torch.Size([16, 64]).
	size mismatch for multihead_attn.w_h.weight: copying a param with shape torch.Size([128, 16]) from checkpoint, the shape in current model is torch.Size([64, 16]).
	size mismatch for post_attn_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for post_attn_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for post_attn_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for post_attn_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc1.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.fc2.weight: copying a param with shape torch.Size([128, 128]) from checkpoint, the shape in current model is torch.Size([64, 64]).
	size mismatch for pos_wise_ff.fc2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pos_wise_ff.gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pos_wise_ff.gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.glu.fc.weight: copying a param with shape torch.Size([256, 128]) from checkpoint, the shape in current model is torch.Size([128, 64]).
	size mismatch for pre_output_gate_norm.glu.fc.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).
	size mismatch for pre_output_gate_norm.add_norm.norm.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for pre_output_gate_norm.add_norm.norm.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).
	size mismatch for output_layer.weight: copying a param with shape torch.Size([7, 128]) from checkpoint, the shape in current model is torch.Size([7, 64]).
